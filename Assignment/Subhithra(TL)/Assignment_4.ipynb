{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53813f6c",
   "metadata": {},
   "source": [
    "# Assignment 4: SMS SPAM Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd9ab4",
   "metadata": {},
   "source": [
    "#### 2. Import required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1bdcc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import string\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Flatten, Dropout\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586f126",
   "metadata": {},
   "source": [
    "#### 3. Read dataset and do pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe2b35f",
   "metadata": {},
   "source": [
    "##### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe64d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\manok\\Documents\\Sem_7\\HX5001-HX6001\\Assignment\\Assignment_4\\spam.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249d550f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acb02812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5f193",
   "metadata": {},
   "source": [
    "##### Drop Unwanted Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67347b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "df = df.rename(columns={\"v2\" : \"Text\", \"v1\":\"Label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b71389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f59099",
   "metadata": {},
   "source": [
    "##### Remove Duplicate and Null Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7f3b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label    0\n",
       "Text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b3d05c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d031c43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(keep='first')\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e00af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e155a07",
   "metadata": {},
   "source": [
    "##### Normalizing the case, Removing the unwanted punctuations, Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b1591fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced8d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "    \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "            \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "            \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80741225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transformed_Text'] = df['Text'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ef06291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Label_enc'] = df['Label'].map({'ham':0,'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edd04b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>Transformed_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                    Transformed_Text  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4               nah think goe usf live around though  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2636812",
   "metadata": {},
   "source": [
    "##### Counting Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b9e4f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "avg_words_len=round(sum([len(i.split()) for i in df['Text']])/len(df['Text']))\n",
    "print(avg_words_len)\n",
    "# avg_words_len=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b0690f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6736\n"
     ]
    }
   ],
   "source": [
    "s = set()\n",
    "for sent in df['Transformed_Text']:\n",
    "  for word in sent.split():\n",
    "    s.add(word)\n",
    "total_words_length=len(s)\n",
    "print(total_words_length)\n",
    "# total_words_length=2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a9dc6f",
   "metadata": {},
   "source": [
    "#### 4. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12c914a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.Transformed_Text\n",
    "y = df.Label\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "435170e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd1736c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4238,), (4238, 1), (931,), (931, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.18, random_state=10)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae645298",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7213749",
   "metadata": {},
   "source": [
    "#### 5. Add Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2965bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = total_words_length, lower = True)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "x_train = sequence.pad_sequences(sequences, maxlen = avg_words_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5dcb3f",
   "metadata": {},
   "source": [
    "##### Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "160ee7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Input(shape=(1), dtype=tf.string))\n",
    "# model.add(Input(name='inputs',shape=[avg_words_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d8faf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(total_words_length, 50, input_length = avg_words_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636bf8a8",
   "metadata": {},
   "source": [
    "##### LSTM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d39d496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c21b08",
   "metadata": {},
   "source": [
    "##### Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e366088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(64, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82851b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcfd0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "020d03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(32, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3403f",
   "metadata": {},
   "source": [
    "##### Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6d1602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d336112",
   "metadata": {},
   "source": [
    "##### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b4017f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 15, 50)            336800    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                29440     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 372,513\n",
      "Trainable params: 372,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee426bd",
   "metadata": {},
   "source": [
    "#### 6. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c587a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss = 'binary_crossentropy', optimizer = RMSprop(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3bede83",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate = 0.001, beta_1 = 0.85, beta_2 = 0.97, epsilon = 1e-07)\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92f0be",
   "metadata": {},
   "source": [
    "#### 7. Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4e0a53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "424/424 [==============================] - 16s 14ms/step - loss: 0.1346 - accuracy: 0.9552\n",
      "Epoch 2/5\n",
      "424/424 [==============================] - 6s 15ms/step - loss: 0.0356 - accuracy: 0.9887\n",
      "Epoch 3/5\n",
      "424/424 [==============================] - 6s 15ms/step - loss: 0.0203 - accuracy: 0.9941\n",
      "Epoch 4/5\n",
      "424/424 [==============================] - 6s 14ms/step - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 5/5\n",
      "424/424 [==============================] - 6s 15ms/step - loss: 0.0043 - accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "history = model.fit(x_train, y_train, epochs = epochs, validation_steps=0.18, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bf954d",
   "metadata": {},
   "source": [
    "#### 8. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a3d0bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"spam_analysis.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88b3180",
   "metadata": {},
   "source": [
    "#### 9. Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1d7e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = sequence.pad_sequences(test_sequences, maxlen=avg_words_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac03cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 2s 10ms/step - loss: 0.2072 - accuracy: 0.9731\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b1b8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(message):\n",
    "    txt = tokenizer.texts_to_sequences(message)\n",
    "    txt = sequence.pad_sequences(txt, maxlen=avg_words_len)\n",
    "    pred = model.predict(txt)\n",
    "    if pred>0.5:\n",
    "        print(\"spam\")\n",
    "    else:\n",
    "        print(\"Harm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5da49335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Harm\n"
     ]
    }
   ],
   "source": [
    "review1 = [\"think he goes\"]\n",
    "predict(review1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7a5a3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "Harm\n"
     ]
    }
   ],
   "source": [
    "review2 = [\"Go until jurong point\"]\n",
    "predict(review2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbe5691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "review3 = [\"WINNER!! As a valued network\"]\n",
    "predict(review3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48a76a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "review4 = [\"URGENT! You have won a 1 week FREE membership\"]\n",
    "predict(review4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
